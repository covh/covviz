{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas\n",
    "sys.path.append(\"..\") \n",
    "sys.path.append(\"../src\") \n",
    "from src import dataFiles, dataMangling, dataPlotting, dataTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = dataMangling.dataMangled()\n",
    "ts, bnn = dataFiles.data(withSynthetic=True)\n",
    "dates = dataMangling.dates_list(ts)\n",
    "ts_BuLa, Bundeslaender = dataMangling.join_tables_for_and_aggregate_Bundeslaender(ts, bnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\\n\".join(ts[ts.ADMIN.isna()][\"AGS\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bundeslaender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fed = dataMangling.get_BuLa(Bundeslaender, \"Hessen\", dm.datacolumns)\n",
    "daily, cumulative, title, filename, population = fed.daily, fed.cumulative, fed.title, fed.filename, fed.population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "center = dataMangling.temporal_center(daily)[0]\n",
    "center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataMangling.temporal_center(fed.daily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bundeslaender.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bundeslaender[\"centerday\"] = [dataMangling.get_BuLa(Bundeslaender, name, dm.datacolumns).center\n",
    "                                  for name in Bundeslaender.index.tolist() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bundeslaender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bundeslaender.sort_values(\"centerday\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bundeslaender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bundeslaender.loc['Deutschland'] = Bundeslaender.sum().values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.drop(ts[ts.ADMIN.isna()].index, inplace=True)\n",
    "\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io, sys\n",
    "\n",
    "import pandas\n",
    "import requests\n",
    "\n",
    "sys.path.append(\"..\") \n",
    "sys.path.append(\"../src\") \n",
    "\n",
    "from dataFiles import OPENDATASOFT_URL01, OPENDATASOFT_URL02, DISTANCES_PATH \n",
    "\n",
    "def download_kreise_locations(url1=OPENDATASOFT_URL01, url2=OPENDATASOFT_URL02):\n",
    "    print (\"Downloading large table with Kreise locations. For infos see\")\n",
    "    print (url1)\n",
    "    print (\"Patience please ...\", end=\" \")\n",
    "    s=requests.get(url2).content\n",
    "    LKG=pandas.read_csv(io.StringIO(s.decode('utf-8')), sep=';') # error_bad_lines=False)\n",
    "    # immediately drop non-Kreis row(s)\n",
    "    LKG.dropna(subset=['Cca 2'],inplace=True)\n",
    "    # turn AGS into integer:\n",
    "    LKG[\"Cca 2\"]=LKG[\"Cca 2\"].astype(int)\n",
    "    print (\"Done downloading.\")\n",
    "    return LKG\n",
    "LKG=download_kreise_locations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LKG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accelerate lookup\n",
    "AGS_to_geopoint=dict(LKG[[\"Cca 2\",\"Geo Point\"]].set_index(\"Cca 2\").to_dict('series')[\"Geo Point\"])\n",
    "AGS_to_geopoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopy.distance\n",
    "\n",
    "def geo_distance(AGS_to_geopoint, AGS1, AGS2):\n",
    "    c1 = list(map(float,AGS_to_geopoint[AGS1].split(\",\")))\n",
    "    c2 = list(map(float,AGS_to_geopoint[AGS2].split(\",\")))\n",
    "    # print (c1, c2 )\n",
    "    return geopy.distance.geodesic(c1, c2).kilometers\n",
    "\n",
    "print (geo_distance(AGS_to_geopoint, 1001, 1002))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_distances_table(AGS_to_geopoint, all_AGS, filename=DISTANCES_PATH):\n",
    "    headers = ['AGS1','AGS2','km']\n",
    "    counter,countermax=0, len(all_AGS)*(len(all_AGS)-1)\n",
    "    distances=pandas.DataFrame([], columns = headers)\n",
    "    for AGS1 in all_AGS:\n",
    "        for AGS2 in all_AGS:\n",
    "            if AGS1>=AGS2:\n",
    "                continue\n",
    "            geodist = geo_distance(AGS_to_geopoint, AGS1, AGS2)\n",
    "            row=pandas.Series([AGS1, AGS2, geodist], index=headers)\n",
    "            distances=distances.append(row, ignore_index=True)\n",
    "            row=pandas.Series([AGS2, AGS1, geodist], index=headers)\n",
    "            distances=distances.append(row, ignore_index=True)\n",
    "            counter+=2\n",
    "            if not counter%100:\n",
    "                print (counter, \"/\", countermax)\n",
    "\n",
    "    print (\"Done calculating distances. Len(table)=%d\" % len(distances))\n",
    "\n",
    "    distances[\"AGS1\"]=distances[\"AGS1\"].astype(int)\n",
    "    distances[\"AGS2\"]=distances[\"AGS2\"].astype(int)\n",
    "        \n",
    "    print (\"Distances are distributed like this:\")\n",
    "    print(distances[\"km\"].describe())\n",
    "    \n",
    "    distances.sort_values(\"km\", inplace=True)\n",
    "    print(\"Done sorting.\")\n",
    "    \n",
    "    distances.to_csv(filename)\n",
    "    print (\"Saved to\", filename)\n",
    "    return distances, filename\n",
    "\n",
    "all_AGS=LKG[\"Cca 2\"].dropna().astype(int).tolist()\n",
    "# all_AGS=all_AGS[:20] # reduce number for dev'ing\n",
    "print(all_AGS)\n",
    "print()\n",
    "\n",
    "distances, filename = make_distances_table(AGS_to_geopoint, all_AGS)\n",
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(distances[(distances.km<150) & (distances.AGS1==9371)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\") \n",
    "sys.path.append(\"../src\") \n",
    "import dataFiles, dataMangling, dataPlotting, districtDistances\n",
    "distances = districtDistances.load_distances()\n",
    "print (districtDistances.nearby(distances, 1001, 50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances[(distances.km<=50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts, bnn = dataFiles.data(withSynthetic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnn.BEZ.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LKG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_risklayer_with_opendatasoft(bnn):\n",
    "    filename = dataFiles.OPENDATASOFT_PATH\n",
    "    LKG = districtDistances.load_kreise_locations(filename)\n",
    "    ODS = set(LKG[\"Cca 2\"].tolist())\n",
    "    ts, bnn = dataFiles.data(withSynthetic=True)\n",
    "    RSL=set(bnn[\"AGS\"].values.tolist())\n",
    "    \n",
    "    diff1 = list(ODS-RSL)\n",
    "    names1=([LKG[\"Name 2\"][LKG[\"Cca 2\"]==AGS].tolist()[0] for AGS in diff1])\n",
    "    print (\"ODS-RSL: %s = %s\"% (diff1, names1))\n",
    "    diff2 = list(RSL-ODS)\n",
    "    names2=([bnn[\"GEN\"][bnn[\"AGS\"]==AGS].tolist()[0] for AGS in diff2])\n",
    "    print (\"RSL-ODS: %s = %s\"% (diff2, names2))\n",
    "compare_risklayer_with_opendatasoft(bnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=LKG[LKG[\"Cca 2\"]==3152].index.tolist()\n",
    "if i:\n",
    "    LKG.at[i, \"Cca 2\"] = 3159"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LKG.loc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=LKG[LKG[\"Cca 2\"]==3156].index.tolist()\n",
    "if i:\n",
    "    LKG.drop(index=i, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LKG[(LKG[\"Cca 2\"]> 3150) & (LKG[\"Cca 2\"]< 3161)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0]\n",
    "list(map(int, a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\") \n",
    "sys.path.append(\"../src\") \n",
    "import dataFiles, dataMangling, dataPlotting, districtDistances,dataTable\n",
    "ts, bnn, ts_sorted, Bundeslaender_sorted, dates, datacolumns = dataMangling.dataMangled()\n",
    "distances = districtDistances.load_distances()\n",
    "cmap = dataTable.colormap()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bundeslaender_sorted.index.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DE=Bundeslaender_sorted.drop([\"Deutschland\", \"Dummyland\"]).sum()\n",
    "DE[datacolumns].astype(int).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DE = Bundeslaender_sorted.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DE[\"Population\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas\n",
    "sys.path.append(\"..\") \n",
    "sys.path.append(\"../src\") \n",
    "import dataFiles, dataMangling, dataPlotting, districtDistances,dataTable\n",
    "dataFiles.TS_NEWEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts=pandas.read_csv(dataFiles.TS_NEWEST, encoding='cp1252') # encoding='utf-8')\n",
    "ts[ts[\"AGS\"]==\"05370\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts[\"28.04.2020\"]=(ts[\"29.04.2020\"]+ts[\"27.04.2020\"])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts[ts[\"AGS\"]==\"05370\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\") \n",
    "sys.path.append(\"../src\") \n",
    "import dataFiles, dataMangling, dataPlotting, districtDistances,dataTable\n",
    "ts, bnn, ts_sorted, Bundeslaender_sorted, dates, datacolumns = dataMangling.dataMangled()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BLs=sorted(Bundeslaender_sorted.index.tolist())\n",
    "BLs = [BL for BL in BLs if BL not in (\"Dummyland\", \"Deutschland\")]\n",
    "\n",
    "global page\n",
    "page=\"\"\n",
    "c=0\n",
    "\n",
    "class page(object):\n",
    "    page=\"\"\n",
    "    def a(self, t):\n",
    "        self.page+=t+\"\\n\"\n",
    "       \n",
    "p=page()\n",
    "p.a(\"<table>\")\n",
    "for i in range(4):\n",
    "    p.a(\"<tr>\")\n",
    "    for j in range(4):\n",
    "        print(c, BLs[c])\n",
    "        imgprop='src=\"https://covh.github.io/cov19de/pics/bundesland_%s.png\" alt=\"bundesland_%s.png\"'%(BLs[c],BLs[c])\n",
    "        p.a('<td><a href=\"%s.html\"><img %s width=\"458\" height=\"268\"></a></td>' % (BLs[c], imgprop))\n",
    "        c+=1\n",
    "    p.a(\"</tr>\")\n",
    "p.a(\"</table>\")\n",
    "print (p.page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AGS_to_cumulative(ts_rich, datacolumns, AGS):\n",
    "    \"\"\"\n",
    "    now also accepts tables with additional columns\n",
    "    \"\"\"\n",
    "    AGS = (\"00000%s\"%AGS)[-5:]\n",
    "    row = ts.loc[ts['AGS'] == AGS]\n",
    "    print \n",
    "    return row[datacolumns].values[0].tolist()\n",
    "print (AGS_to_cumulative(ts_rich=ts_sorted, datacolumns=datacolumns, AGS=1001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas, numpy\n",
    "\n",
    "def AGS_to_cumulative(ts_rich, datacolumns, AGS):\n",
    "    \"\"\"\n",
    "    now also accepts tables with additional columns\n",
    "    because positive selection by datacolumns (not negative by droppping columns)  \n",
    "    \"\"\"\n",
    "    AGS = (\"00000%s\"%AGS)[-5:]\n",
    "    row = ts.loc[ts['AGS'] == AGS]\n",
    "    print \n",
    "    return row[datacolumns].values[0].tolist()\n",
    "\n",
    "\n",
    "def AGS_to_daily(ts_rich, datacolumns, AGS):\n",
    "    \"\"\"\n",
    "    now also accepts tables with additional columns\n",
    "    because positive selection by datacolumns (not negative by droppping columns)  \n",
    "    \"\"\"\n",
    "    cum = pandas.Series ( AGS_to_cumulative(ts_rich, datacolumns, AGS) ) \n",
    "    diff = cum.diff()\n",
    "    return diff.values.tolist()\n",
    "\n",
    "AGS=5370\n",
    "print (AGS_to_cumulative(ts_rich=ts_sorted, datacolumns=datacolumns, AGS=AGS))\n",
    "print (AGS_to_daily(ts_rich=ts_sorted, datacolumns=datacolumns, AGS=AGS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AGS=1001\n",
    "AGS=5370\n",
    "cumulative=AGS_to_cumulative(ts_rich=ts_sorted, datacolumns=datacolumns, AGS=AGS)\n",
    "\n",
    "def cumulative_smoothed_last_week_incidence(cumulative, windowsize=7, daysBack=7):\n",
    "    averaged=pandas.DataFrame(cumulative).rolling(window=windowsize, center=False).mean()[0].values.tolist()\n",
    "    return averaged[-1]-averaged[-daysBack]\n",
    "cumulative_smoothed_last_week_incidence(cumulative)\n",
    "\n",
    "def cumulative_today_minus_last_week_smoothed(cumulative, windowsize=7, daysBack=7):\n",
    "    averaged=pandas.DataFrame(cumulative).rolling(window=windowsize, center=True).mean()[0].values.tolist()\n",
    "    return cumulative[-1] - averaged[-daysBack]\n",
    "cumulative_today_minus_last_week_smoothed(cumulative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_rich = ts_sorted\n",
    "ts_rich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_rich.loc[7135][datacolumns].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bundeslaender_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiDayIncidence(cumulative, daysBack=7):\n",
    "    \"\"\"\n",
    "    unaveraged, will probably work best for daysBack=7 or 14 or 21 \n",
    "    \"\"\"\n",
    "    return cumulative[-1] - cumulative[-daysBack-1]\n",
    "\n",
    "\n",
    "def add_incidence_columns(ts_rich):\n",
    "    \n",
    "    for days in (7, 14):\n",
    "        ts_rich[\"incidence_last%days\" % days] = [ multiDayIncidence( AGS_to_cumulative(ts_rich, datacolumns, AGS) , days)\n",
    "                                                  for AGS in ts_rich.index.values.tolist() ]\n",
    "    return ts_sorted\n",
    "\n",
    "\n",
    "def add_incidence_columns_Bundeslaender(Bundeslaender):\n",
    "    \n",
    "    for days in (7, 14):\n",
    "        colname = \"incidence_last%ddays\" % days\n",
    "        Bundeslaender[colname] = [ multiDayIncidence(  get_BuLa(Bundeslaender, name, dm.datacolumns).cumulative , days)\n",
    "                                  for name in Bundeslaender.index.tolist() ]\n",
    "\n",
    "    return Bundeslaender\n",
    "\n",
    "\n",
    "add_incidence_columns(ts_sorted)\n",
    "add_incidence_columns_Bundeslaender(Bundeslaender_sorted)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AGS_to_cumulative(ts_sorted, datacolumns, AGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataMangling import get_BuLa\n",
    "add_incidence_columns_Bundeslaender(Bundeslaender_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ multiDayIncidence( AGS_to_cumulative(ts_sorted, datacolumns, AGS) , days)\n",
    "                                                  for AGS in ts_sorted[\"AGS\"].tolist() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "multiDayIncidence( AGS_to_cumulative(ts_rich, datacolumns, AGS) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_rich.index.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_incidence_columns(ts_rich):\n",
    "    \n",
    "    for days in (7, 14):\n",
    "        ts_rich[\"incidence_last%days\" % days] = [ multiDayIncidence( AGS_to_cumulative(ts_rich, datacolumns, AGS) , days)\n",
    "                                                  for AGS in ts_rich.index.values.tolist() ]\n",
    "    return ts_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy,matplotlib,pandas\n",
    "sys.path.append(\"..\") \n",
    "sys.path.append(\"../src\") \n",
    "import dataFiles, dataMangling, dataPlotting, districtDistances,dataTable\n",
    "ts, bnn, ts_sorted, Bundeslaender_sorted, dates, datacolumns = dataMangling.dataMangled()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bundeslaender_sorted\n",
    "ts_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AGS=9377\n",
    "AGS=9479\n",
    "AGS=16076\n",
    "cumulative=ts_sorted.loc[AGS][datacolumns].tolist()\n",
    "daily=ts_sorted.loc[AGS][datacolumns].diff().tolist()\n",
    "daily_SMA=pandas.DataFrame(daily).rolling(window=7, center=True).mean()[0].values.tolist()\n",
    "daily_SMA\n",
    "list(zip(cumulative,daily, daily_SMA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Reff_4_4(daily,i):\n",
    "    if i<7:\n",
    "        return numpy.nan\n",
    "    d=daily\n",
    "    denominator = d[i-4]+d[i-5]+d[i-6]+d[i-7]\n",
    "    result = (d[i]+d[i-1]+d[i-2]+d[i-3]) / denominator if denominator else numpy.nan\n",
    "    return result \n",
    "\n",
    "def Reff_4_7(daily,i):\n",
    "    if i<10:\n",
    "        return numpy.nan\n",
    "    d=daily\n",
    "    denominator = d[i-4]+d[i-5]+d[i-6]+d[i-7]+d[i-8]+d[i-9]+d[i-10]\n",
    "    result = (d[i]+d[i-1]+d[i-2]+d[i-3]+d[i-4]+d[i-5]+d[i-6]) / denominator if denominator else numpy.nan\n",
    "    return result \n",
    "\n",
    "R1=[Reff_4_4(daily, i) for i, _ in enumerate(daily)]\n",
    "R2=[Reff_4_7(daily, i) for i, _ in enumerate(daily)]\n",
    "R3=[Reff_4_4(daily_SMA, i) for i, _ in enumerate(daily_SMA)]\n",
    "\n",
    "R1\n",
    "matplotlib.pyplot.plot(R1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bundeslaender_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3science",
   "language": "python",
   "name": "py3science"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}